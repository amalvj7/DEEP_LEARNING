{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bh8Jc28NWy7Z"
   },
   "source": [
    "# Problem Statement: **Threat Classification for AtliQ Wildlife Reserve**\n",
    "\n",
    "### Welcome to the AtliQ Wildlife Reserve, a sanctuary where technology helps preserve wildlife. You are tasked with developing AI systems to monitor, classify, and predict behaviors of animals in the sanctuary.\n",
    "\n",
    "\n",
    "**References:**\n",
    "\n",
    "* PyTorch Dataset and Dataloader [link](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n",
    "* Seaborn Heatmaps [link](https://seaborn.pydata.org/generated/seaborn.heatmap.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5MqurUZXGoU"
   },
   "source": [
    "Imports and CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9kq7PLN6WEo3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Check if CUDA (GPU) is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXD3uwVpHjMc"
   },
   "source": [
    "## Let's do some revision first!\n",
    "\n",
    "**Problem1.** AtliQ Warehouse\n",
    "\n",
    "Your task is to define a simple neural network that will predict whether AtliQ's warehouses are running an optimal stock level for a given product (binary classification). The neural network should include:\n",
    "\n",
    "* An input layer of size 128 (representing features such as sales trends, regional demand, and supplier reliability).\n",
    "* Two hidden layers, each with 64 neurons.\n",
    "* An output layer that predicts the stock status (1 for optimal, 0 for not optimal).\n",
    "\n",
    "\n",
    "**Hint:** Use nn.Sequential to define the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VruFTaiIHm9Q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "   nn.Linear(128 , 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64 , 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64 , 2)  \n",
    ")\n",
    "\n",
    "# Print the model structure\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKM7R8qtISyy"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ye_04NuH5Ms"
   },
   "source": [
    "**Problem2.** Sales data at AtliQ\n",
    "\n",
    "AtliQ's data analytics team has provided sales data in NumPy format for your AI models. The data,\n",
    "\n",
    "` data = np.array([1, 2, 3, 4, 5])`,\n",
    "\n",
    " represents product sales in a given week. Your task is to:\n",
    "\n",
    "Convert this NumPy array into a PyTorch tensor of type float32.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KA0qDRm2H9HH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4., 5.])\n"
     ]
    }
   ],
   "source": [
    "# Create a NumPy array\n",
    "data =np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "# Convert the NumPy array to a PyTorch tensor of type float32\n",
    "tensor_data = torch.tensor(data , dtype = torch.float32)\n",
    "\n",
    "# Print the tensor\n",
    "print(tensor_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oA20Ywx9IT6-"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GWUBNL9hIE9B"
   },
   "source": [
    "**Problem3.** Customer Classification at AtliQ\n",
    "\n",
    "AtliQ's marketing team is running an AI model to classify customers into 3 distinct segments based on purchasing behavior. Your task is to:\n",
    "\n",
    "* Simulate raw logits from the model's output.\n",
    "* Generate random target labels for a 3-class classification task\n",
    "* Compute the classification loss using nn.CrossEntropyLoss\n",
    "\n",
    "**Hint**: Use torch.randint() for generating random target labels and nn.CrossEntropyLoss() for the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "frkwQz0vIGxS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Entropy Loss: 1.0845\n"
     ]
    }
   ],
   "source": [
    "logits = torch.tensor([[1.0, 2.0, 0.5], [1.5, 0.2, 1.7], [0.4, 0.8, 2.1]], dtype=torch.float32)\n",
    "\n",
    "labels = torch.tensor([1, 2, 0], dtype=torch.long)\n",
    "\n",
    "# Define the CrossEntropyLoss function\n",
    "loss_fun = loss_fun = nn.CrossEntropyLoss()\n",
    "\n",
    "# Compute the loss\n",
    "loss =loss = loss_fun(logits, labels)\n",
    "\n",
    "print(f\"Cross-Entropy Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wSO1nyKkCKmI"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cg8Swd2YAWD"
   },
   "source": [
    "### **Task:** Habitat Threat Detector\n",
    "\n",
    "In the sanctuary, camera drones monitor animal habitats for threats like poaching activities or habitat damage. Your task as an AI Engineer is to build an AI system to detect whether an image shows a threat from the provided dataset **(habitat_images_codebasics_DL.csv)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIokYWC0YP4L"
   },
   "source": [
    "**Dataset Overview**\n",
    "\n",
    "The dataset **habitat_images_codebasics_DL.csv** contains the following features:\n",
    "\n",
    "* Image Brightness (float): Represents how bright or dark the image is.\n",
    "* Movement Intensity (float): Measures activity detected in the image.\n",
    "* Number of Shapes Detected (integer): Indicates potential objects in the image.\n",
    "* Noise Level (float): A measure of distortions in the image.\n",
    "* Threat Label (0 or 1): 0 for no threat, 1 for a threat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_9Qhmdfb-i6"
   },
   "source": [
    "**Step 1:** Load and Split the Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Rogs1y3WZetS"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"habitat_images_codebasics_DL.csv\")\n",
    "\n",
    "# Separate input features and labels\n",
    "X = df[[\"Image Brightness\" ,\"Number of Shapes Detected\" , \"Movement Intensity\" , \"Noise Level\"]].values\n",
    "y = df[[\"Threat Label\"]].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Brightness</th>\n",
       "      <th>Movement Intensity</th>\n",
       "      <th>Number of Shapes Detected</th>\n",
       "      <th>Noise Level</th>\n",
       "      <th>Threat Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.437086</td>\n",
       "      <td>0.314292</td>\n",
       "      <td>19</td>\n",
       "      <td>0.186741</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.955643</td>\n",
       "      <td>6.364104</td>\n",
       "      <td>10</td>\n",
       "      <td>4.113003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.758795</td>\n",
       "      <td>3.143560</td>\n",
       "      <td>16</td>\n",
       "      <td>1.800953</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.638793</td>\n",
       "      <td>5.085707</td>\n",
       "      <td>7</td>\n",
       "      <td>0.635303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.240417</td>\n",
       "      <td>9.075665</td>\n",
       "      <td>3</td>\n",
       "      <td>2.611216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Image Brightness  Movement Intensity  Number of Shapes Detected  \\\n",
       "0          0.437086            0.314292                         19   \n",
       "1          0.955643            6.364104                         10   \n",
       "2          0.758795            3.143560                         16   \n",
       "3          0.638793            5.085707                          7   \n",
       "4          0.240417            9.075665                          3   \n",
       "\n",
       "   Noise Level  Threat Label  \n",
       "0     0.186741             0  \n",
       "1     4.113003             0  \n",
       "2     1.800953             0  \n",
       "3     0.635303             0  \n",
       "4     2.611216             0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_vNDgGL0CgGg"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEeQyboLTPp7"
   },
   "source": [
    "**Step 2:** Normalize the input feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "pIGSwZ2BTUbI"
   },
   "outputs": [],
   "source": [
    "X = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B6bZjpy1CNsy"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GiDwdn7ATcTZ"
   },
   "source": [
    "**Step3:** Convert to PyTorch tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "adHSY6CYTlyT"
   },
   "outputs": [],
   "source": [
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).unsqueeze(1)  # Reshape to match the model output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4liDHApDCOZS"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4qB9eZCTmVj"
   },
   "source": [
    "**Step4**: Perform an **70%-30%** train-validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "oW355OZ2TnEf"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X , y,test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8vOlfDOCSP_"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqR6Q2xXT9kN"
   },
   "source": [
    "**Step5**: Create DataLoader for batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "hfVYt4wRUAgV"
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(X_train , y_train)\n",
    "test_data = TensorDataset(X_test , y_test)\n",
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEEbzWfpCWJd"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MZtV-f_cMi9"
   },
   "source": [
    "**Step 6:** Define the Neural Network\n",
    "\n",
    "* Input layer with 4 features.\n",
    "* One hidden layer with 8 neurons (ReLU activation).\n",
    "* Output layer with 1 neuron (Sigmoid activation for binary classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OzjTQoEYcXv-"
   },
   "outputs": [],
   "source": [
    "class ThreatDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ThreatDetector, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(4 , 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8 , 8)   # Output: 1 neuron\n",
    "            nn.Sigmoid()   \n",
    "            nn.Linear(8 ,1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Instantiate the model\n",
    "model = # Code Here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdGIL4AgCXbO"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geUtDQ-AUghS"
   },
   "source": [
    "**Step7**: Define Loss and Optimizer\n",
    "\n",
    "* Optimizer: Adam\n",
    "* Loss: BCE Loss\n",
    "* Learning rate: 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0lCy2REGUl5A"
   },
   "outputs": [],
   "source": [
    "# Binary Cross-Entropy Loss\n",
    "BCE_loss = # Code Here\n",
    "\n",
    "# Adam Optimizer\n",
    "optimizer =# Code Here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhvb58nVCY1M"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMDovUEJcZe0"
   },
   "source": [
    "**Step 8**: Train the Neural Network\n",
    "\n",
    "* Train the model for 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "edU_flFQdgMH"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, BCE_loss, optimizer, epochs=20):\n",
    "    # Code Here\n",
    "\n",
    "            # Forward pass\n",
    "\n",
    "\n",
    "            # Backward pass\n",
    "\n",
    "\n",
    "            # Accumulate loss\n",
    "\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, BCE_loss, optimizer, epochs=)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qGsCOWreCZ2F"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s7YoTEEddiwA"
   },
   "source": [
    "**Step 9:** Evaluate the Model\n",
    "\n",
    "* Calculate the accuracy and loss on a test dataset.\n",
    "* Use a confusion matrix to evaluate the systemâ€™s performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rxDluCzUWBls"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    # Code Here\n",
    "\n",
    "    # Convert predictions to binary (threshold = 0.5)\n",
    "    y_pred_binary = # Code Here\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = # Code Here\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = # Code Here\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2inPw3AICa1E"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
